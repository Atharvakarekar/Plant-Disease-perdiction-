{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19801e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70294 images belonging to 38 classes.\n",
      "Found 17572 images belonging to 38 classes.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Pratima\\\\Documents\\\\GitHub\\\\Plant-Disease-perdiction-\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\\\\Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\\\\13e25fae-97ee-44c0-92c0-05328de64148___RS_GLSp 4645_new30degFlipLR.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 57>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m validation_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(validation_data_dir,\n\u001b[0;32m     52\u001b[0m                                                               target_size\u001b[38;5;241m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     53\u001b[0m                                                               batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     54\u001b[0m                                                               class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_validation_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     64\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplant_disease_detection_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Pratima\\\\Documents\\\\GitHub\\\\Plant-Disease-perdiction-\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\\\\Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\\\\13e25fae-97ee-44c0-92c0-05328de64148___RS_GLSp 4645_new30degFlipLR.JPG'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Set the input image dimensions and number of classes\n",
    "img_width, img_height = 224, 224\n",
    "num_classes = 2\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the paths to your training and validation data directories\n",
    "train_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "validation_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid'\n",
    "\n",
    "# Set the batch size and number of training steps per epoch\n",
    "batch_size = 32\n",
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "epochs = 10\n",
    "\n",
    "# Apply data augmentation to enrich the training dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# Normalize the validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# Load and preprocess the validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              target_size=(img_width, img_height),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=num_train_samples // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=num_validation_samples // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('plant_disease_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2043b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70293 images belonging to 38 classes.\n",
      "Found 17572 images belonging to 38 classes.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0384 - accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.6368e-07 - accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4116 - accuracy: 0.9375\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6811 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6600 - accuracy: 0.0625\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9478 - accuracy: 0.9375\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Set the input image dimensions and number of classes\n",
    "img_width, img_height = 224, 224\n",
    "num_classes = 2\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the paths to your training and validation data directories\n",
    "train_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "validation_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid'\n",
    "\n",
    "# Set the batch size and number of training steps per epoch\n",
    "batch_size = 32\n",
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "epochs = 10\n",
    "\n",
    "# Apply data augmentation to enrich the training dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# Normalize the validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# Load and preprocess the validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              target_size=(img_width, img_height),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "for _ in range(epochs):\n",
    "    try:\n",
    "        x_train, y_train = next(train_generator)\n",
    "        model.fit(x_train, tf.one_hot(tf.argmax(y_train, axis=1), num_classes))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "# Save the trained model\n",
    "model.save('plant_disease_detection_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47741c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68653 images belonging to 37 classes.\n",
      "Found 17162 images belonging to 37 classes.\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 659s 11s/step - loss: 2.9029 - accuracy: 0.2686 - val_loss: 1.9967 - val_accuracy: 0.4588\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 703s 11s/step - loss: 1.5637 - accuracy: 0.5605 - val_loss: 1.1791 - val_accuracy: 0.6475\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 721s 12s/step - loss: 1.0983 - accuracy: 0.6774 - val_loss: 0.9562 - val_accuracy: 0.6900\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 608s 10s/step - loss: 0.8922 - accuracy: 0.7389 - val_loss: 0.8344 - val_accuracy: 0.7400\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 643s 10s/step - loss: 0.7491 - accuracy: 0.7656 - val_loss: 0.6511 - val_accuracy: 0.7937\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 890s 14s/step - loss: 0.6854 - accuracy: 0.7873 - val_loss: 0.7630 - val_accuracy: 0.7638\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 842s 14s/step - loss: 0.5988 - accuracy: 0.8090 - val_loss: 0.5874 - val_accuracy: 0.8238\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 769s 12s/step - loss: 0.6850 - accuracy: 0.7898 - val_loss: 0.6359 - val_accuracy: 0.7962\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 1006s 16s/step - loss: 0.5814 - accuracy: 0.8150 - val_loss: 0.5010 - val_accuracy: 0.8300\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 554s 9s/step - loss: 0.5062 - accuracy: 0.8377 - val_loss: 0.5414 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Set the input image dimensions and number of classes\n",
    "img_width, img_height = 224, 224\n",
    "num_classes = 37\n",
    "class_labels = ['class_{}'.format(i) for i in range(num_classes)]\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the paths to your training and validation data directories\n",
    "train_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "validation_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid'\n",
    "\n",
    "# Set the batch size and number of training steps per epoch\n",
    "batch_size = 32\n",
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "epochs = 10\n",
    "\n",
    "# Apply data augmentation to enrich the training dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# Normalize the validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# Load and preprocess the validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              target_size=(img_width, img_height),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=num_train_samples // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=num_validation_samples // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('plant_disease_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7dc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68653 images belonging to 37 classes.\n",
      "Found 17162 images belonging to 37 classes.\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 640s 10s/step - loss: 2.9627 - accuracy: 0.2475 - val_loss: 1.9811 - val_accuracy: 0.4688\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 637s 10s/step - loss: 1.5854 - accuracy: 0.5590 - val_loss: 1.1320 - val_accuracy: 0.6775\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 599s 10s/step - loss: 1.1934 - accuracy: 0.6507 - val_loss: 0.9330 - val_accuracy: 0.7275\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 562s 9s/step - loss: 0.9119 - accuracy: 0.7263 - val_loss: 0.8774 - val_accuracy: 0.7262\n",
      "Epoch 5/10\n",
      "14/62 [=====>........................] - ETA: 6:59 - loss: 0.8631 - accuracy: 0.7679"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Set the input image dimensions and number of classes\n",
    "img_width, img_height = 224, 224\n",
    "num_classes = 37\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['class_{}'.format(i) for i in range(num_classes)]\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the paths to your training and validation data directories\n",
    "train_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "validation_data_dir = r'C:\\Users\\Pratima\\Documents\\GitHub\\Plant-Disease-perdiction-\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid'\n",
    "\n",
    "# Set the batch size and number of training steps per epoch\n",
    "batch_size = 32\n",
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "epochs = 10\n",
    "\n",
    "# Apply data augmentation to enrich the training dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# Normalize the validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# Load and preprocess the validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              target_size=(img_width, img_height),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=num_train_samples // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=num_validation_samples // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('plant_disease_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f73285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
